{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# AI-Based Tomato & Potato Disease Classification - Google Colab Training\n",
    "\n",
    "**Author:** Peter Maina (136532)  \n",
    "**Institution:** Strathmore University  \n",
    "**Project:** Final Year AI/ML Project  \n",
    "\n",
    "This notebook implements the complete training pipeline for plant disease classification on Google Colab.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup Environment](#setup)\n",
    "2. [Download Dataset](#download)\n",
    "3. [Data Exploration](#exploration)\n",
    "4. [Data Preprocessing](#preprocessing)\n",
    "5. [Model Training](#training)\n",
    "6. [Model Evaluation](#evaluation)\n",
    "7. [Model Export](#export)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's check GPU availability and clone the project repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"\\nGPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Enable GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - for saving models)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"✓ Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone project repository\n",
    "!git clone https://github.com/YOUR_USERNAME/AI-Based-Tomato-and-Potato-Disease-Classification-App.git\n",
    "%cd AI-Based-Tomato-and-Potato-Disease-Classification-App\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pyyaml\n",
    "!pip install -q kaggle\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q seaborn\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaggle-setup-header"
   },
   "source": [
    "### Setup Kaggle API\n",
    "\n",
    "Upload your `kaggle.json` file to access the PlantVillage dataset.\n",
    "\n",
    "**How to get kaggle.json:**\n",
    "1. Go to https://www.kaggle.com/settings\n",
    "2. Scroll to API section\n",
    "3. Click \"Create New API Token\"\n",
    "4. Upload the downloaded file below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-kaggle"
   },
   "outputs": [],
   "source": [
    "# Upload kaggle.json\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"\\n✓ Kaggle credentials configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 2. Download Dataset\n",
    "\n",
    "Download the PlantVillage dataset from Kaggle (4.37 GB, ~54,000 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset"
   },
   "outputs": [],
   "source": [
    "# Download PlantVillage dataset\n",
    "!python data/scripts/download_dataset.py --colab-mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exploration-header"
   },
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Explore the dataset structure and visualize sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore-structure"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "# Load configuration\n",
    "with open('data/configs/data_config.yaml', 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(f\"  Total Images: {data_config['dataset']['total_images']:,}\")\n",
    "print(f\"  Size: {data_config['dataset']['size_gb']} GB\")\n",
    "print(f\"  Number of Classes: {data_config['num_classes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-samples"
   },
   "outputs": [],
   "source": [
    "# Visualize sample images from each crop\n",
    "def visualize_samples(data_dir, crop_type, n_samples=6):\n",
    "    \"\"\"Visualize sample images from a crop type.\"\"\"\n",
    "    crop_dir = Path(data_dir) / crop_type\n",
    "    \n",
    "    if not crop_dir.exists():\n",
    "        print(f\"Directory not found: {crop_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Get first disease class\n",
    "    disease_classes = [d for d in crop_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'{crop_type.upper()} Sample Images', fontsize=16)\n",
    "    \n",
    "    for idx, disease_dir in enumerate(disease_classes[:n_samples]):\n",
    "        # Get first image\n",
    "        image_files = list(disease_dir.glob('*.jpg')) + list(disease_dir.glob('*.png'))\n",
    "        if image_files:\n",
    "            img = Image.open(image_files[0])\n",
    "            \n",
    "            row = idx // 3\n",
    "            col = idx % 3\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].set_title(disease_dir.name, fontsize=10)\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize tomato samples\n",
    "visualize_samples('data/raw', 'tomato')\n",
    "\n",
    "# Visualize potato samples\n",
    "visualize_samples('data/raw', 'potato', n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class-distribution"
   },
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "def analyze_distribution(data_dir):\n",
    "    \"\"\"Analyze and visualize class distribution.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    class_counts = {}\n",
    "    \n",
    "    for crop in ['tomato', 'potato']:\n",
    "        crop_dir = data_dir / crop\n",
    "        if crop_dir.exists():\n",
    "            for disease_dir in crop_dir.iterdir():\n",
    "                if disease_dir.is_dir():\n",
    "                    image_files = list(disease_dir.glob('*.jpg')) + list(disease_dir.glob('*.png'))\n",
    "                    class_counts[disease_dir.name] = len(image_files)\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(range(len(class_counts)), list(class_counts.values()))\n",
    "    plt.xticks(range(len(class_counts)), list(class_counts.keys()), rotation=45, ha='right')\n",
    "    plt.xlabel('Disease Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    total = sum(class_counts.values())\n",
    "    print(f\"\\nTotal Images: {total:,}\")\n",
    "    print(f\"Min Images per Class: {min(class_counts.values()):,}\")\n",
    "    print(f\"Max Images per Class: {max(class_counts.values()):,}\")\n",
    "    print(f\"Average Images per Class: {total/len(class_counts):.0f}\")\n",
    "\n",
    "analyze_distribution('data/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocessing-header"
   },
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Preprocess images and split into train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess-data"
   },
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "!python data/scripts/preprocess_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "split-dataset"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train/val/test\n",
    "!python data/scripts/split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-header"
   },
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Train different model architectures:\n",
    "- Baseline CNN\n",
    "- MobileNetV2 (recommended for mobile deployment)\n",
    "- EfficientNetB0 (best accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-mobilenet"
   },
   "outputs": [],
   "source": [
    "# Train MobileNetV2 model (recommended)\n",
    "!python ml/training.py --architecture MobileNetV2 --epochs 50 --batch-size 32 --use-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-baseline"
   },
   "outputs": [],
   "source": [
    "# Optional: Train Baseline CNN\n",
    "# !python ml/training.py --architecture baseline --epochs 50 --batch-size 32 --use-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-efficientnet"
   },
   "outputs": [],
   "source": [
    "# Optional: Train EfficientNetB0 (best accuracy, slower training)\n",
    "# !python ml/training.py --architecture EfficientNetB0 --epochs 50 --batch-size 32 --use-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-training-header"
   },
   "source": [
    "### Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-training"
   },
   "outputs": [],
   "source": [
    "# Load and visualize training history\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(0, '/content/AI-Based-Tomato-and-Potato-Disease-Classification-App')\n",
    "from ml.utils import plot_training_history\n",
    "\n",
    "# Find latest training history file\n",
    "history_dir = Path('ml/logs/training')\n",
    "history_files = list(history_dir.glob('*_history.json'))\n",
    "\n",
    "if history_files:\n",
    "    # Load most recent history\n",
    "    latest_history = sorted(history_files)[-1]\n",
    "    print(f\"Loading history from: {latest_history}\")\n",
    "    \n",
    "    with open(latest_history, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "else:\n",
    "    print(\"No training history found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation-header"
   },
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "find-best-model"
   },
   "outputs": [],
   "source": [
    "# Find the best trained model\n",
    "model_dir = Path('ml/trained_models/final')\n",
    "model_files = list(model_dir.glob('*.h5'))\n",
    "\n",
    "if model_files:\n",
    "    best_model = sorted(model_files)[-1]\n",
    "    print(f\"Found model: {best_model}\")\n",
    "else:\n",
    "    print(\"No trained models found\")\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-model"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "if best_model:\n",
    "    !python ml/evaluation.py --model {best_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference-header"
   },
   "source": [
    "### Test Inference on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-inference"
   },
   "outputs": [],
   "source": [
    "# Test inference on a sample image\n",
    "from ml.inference import predict_single_image\n",
    "\n",
    "# Get a sample test image\n",
    "test_dir = Path('data/processed/test')\n",
    "test_classes = list(test_dir.iterdir())\n",
    "\n",
    "if test_classes and best_model:\n",
    "    # Get first image from first class\n",
    "    sample_class = test_classes[0]\n",
    "    image_files = list(sample_class.glob('*.jpg')) + list(sample_class.glob('*.png'))\n",
    "    \n",
    "    if image_files:\n",
    "        sample_image = image_files[0]\n",
    "        print(f\"Testing on: {sample_image}\")\n",
    "        print(f\"True class: {sample_class.name}\\n\")\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_class, confidence = predict_single_image(\n",
    "            str(best_model),\n",
    "            str(sample_image),\n",
    "            visualize=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": [
    "## 7. Model Export\n",
    "\n",
    "Convert model to TensorFlow Lite format for mobile deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "convert-tflite"
   },
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite\n",
    "from ml.utils import convert_to_tflite\n",
    "\n",
    "if best_model:\n",
    "    tflite_model = convert_to_tflite(\n",
    "        str(best_model),\n",
    "        quantization='float16'\n",
    "    )\n",
    "    print(f\"\\n✓ TFLite model saved: {tflite_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save-header"
   },
   "source": [
    "### Save Models to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-to-drive"
   },
   "outputs": [],
   "source": [
    "# Copy models to Google Drive for persistence\n",
    "import shutil\n",
    "\n",
    "drive_model_dir = Path('/content/drive/MyDrive/PlantDiseaseModels')\n",
    "drive_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy trained models\n",
    "if best_model:\n",
    "    shutil.copy(best_model, drive_model_dir)\n",
    "    print(f\"✓ Model saved to: {drive_model_dir / best_model.name}\")\n",
    "\n",
    "# Copy TFLite model\n",
    "if best_model:\n",
    "    tflite_path = best_model.parent / f\"{best_model.stem}.tflite\"\n",
    "    if tflite_path.exists():\n",
    "        shutil.copy(tflite_path, drive_model_dir)\n",
    "        print(f\"✓ TFLite model saved to: {drive_model_dir / tflite_path.name}\")\n",
    "\n",
    "# Copy evaluation reports\n",
    "eval_files = list(Path('ml/logs').glob('*_evaluation.*'))\n",
    "for eval_file in eval_files:\n",
    "    shutil.copy(eval_file, drive_model_dir)\n",
    "    print(f\"✓ Evaluation report saved: {drive_model_dir / eval_file.name}\")\n",
    "\n",
    "print(\"\\n✓ All models and reports saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Training Complete!**\n",
    "\n",
    "You have successfully:\n",
    "1. ✓ Downloaded and explored the PlantVillage dataset\n",
    "2. ✓ Preprocessed and split the data\n",
    "3. ✓ Trained a deep learning model\n",
    "4. ✓ Evaluated model performance\n",
    "5. ✓ Converted model to TFLite format\n",
    "6. ✓ Saved models to Google Drive\n",
    "\n",
    "**Next Steps:**\n",
    "- Download the TFLite model for mobile app integration\n",
    "- Review evaluation metrics and confusion matrix\n",
    "- Fine-tune hyperparameters if needed\n",
    "- Deploy the model in a mobile application\n",
    "\n",
    "**Expected Performance:**\n",
    "- Baseline CNN: 85-90% accuracy\n",
    "- MobileNetV2: 92-95% accuracy\n",
    "- EfficientNetB0: 95-97% accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "colab_training.ipynb",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
